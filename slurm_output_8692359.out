============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
[rank: 0] Seed set to 0
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-40GB MIG 3g.20gb') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [MIG-71410132-ba51-54d4-84db-e854d69891f7]
Namespace(txt_file='./assets/book_EN_grimms_fairy_tales.txt', model_type='gpt-mini', block_size=128, use_pretrained=False, abs_emb=False, train_batch_size=128, generate_batch_size=5, generate_every_n_steps=1000, learning_rate=0.0005, weight_decay=0.1, betas=(0.9, 0.95), num_epochs=5, clip_grad_norm=1.0, log_dir='./logs', seed=0, num_workers=8, progress_bar=False, use_flash_attn=False, precision='32', compile=True, pretrained_tokenizer=False, device='cuda')
data has 540241 characters, 87 unique.
True False
number of parameters: 10.73M
running on device cpu
Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:167: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Finding best initial lr:   1%|          | 1/100 [00:23<38:50, 23.54s/it]Finding best initial lr:   3%|▎         | 3/100 [00:23<10:02,  6.21s/it]Finding best initial lr:   4%|▍         | 4/100 [00:24<06:37,  4.14s/it]Finding best initial lr:   5%|▌         | 5/100 [00:24<04:29,  2.84s/it]Finding best initial lr:   6%|▌         | 6/100 [00:24<03:07,  1.99s/it]Finding best initial lr:   7%|▋         | 7/100 [00:24<02:13,  1.43s/it]Finding best initial lr:   8%|▊         | 8/100 [00:24<01:37,  1.05s/it]Finding best initial lr:   9%|▉         | 9/100 [00:25<01:12,  1.26it/s]Finding best initial lr:  10%|█         | 10/100 [00:25<00:55,  1.62it/s]Finding best initial lr:  11%|█         | 11/100 [00:25<00:43,  2.03it/s]Finding best initial lr:  12%|█▏        | 12/100 [00:25<00:35,  2.45it/s]Finding best initial lr:  13%|█▎        | 13/100 [00:25<00:30,  2.87it/s]Finding best initial lr:  14%|█▍        | 14/100 [00:26<00:26,  3.26it/s]Finding best initial lr:  15%|█▌        | 15/100 [00:26<00:23,  3.61it/s]Finding best initial lr:  16%|█▌        | 16/100 [00:26<00:21,  3.89it/s]Finding best initial lr:  17%|█▋        | 17/100 [00:26<00:20,  4.12it/s]Finding best initial lr:  18%|█▊        | 18/100 [00:26<00:19,  4.30it/s]Finding best initial lr:  19%|█▉        | 19/100 [00:27<00:18,  4.42it/s]Finding best initial lr:  20%|██        | 20/100 [00:27<00:17,  4.52it/s]Finding best initial lr:  21%|██        | 21/100 [00:27<00:17,  4.59it/s]Finding best initial lr:  22%|██▏       | 22/100 [00:27<00:16,  4.64it/s]Finding best initial lr:  23%|██▎       | 23/100 [00:28<00:16,  4.68it/s]Finding best initial lr:  24%|██▍       | 24/100 [00:28<00:16,  4.70it/s]Finding best initial lr:  25%|██▌       | 25/100 [00:28<00:15,  4.72it/s]Finding best initial lr:  26%|██▌       | 26/100 [00:28<00:15,  4.74it/s]Finding best initial lr:  27%|██▋       | 27/100 [00:28<00:15,  4.74it/s]Finding best initial lr:  28%|██▊       | 28/100 [00:29<00:15,  4.75it/s]Finding best initial lr:  29%|██▉       | 29/100 [00:29<00:14,  4.75it/s]Finding best initial lr:  30%|███       | 30/100 [00:29<00:14,  4.76it/s]Finding best initial lr:  31%|███       | 31/100 [00:29<00:14,  4.76it/s]Finding best initial lr:  32%|███▏      | 32/100 [00:29<00:14,  4.76it/s]Finding best initial lr:  33%|███▎      | 33/100 [00:30<00:14,  4.76it/s]Finding best initial lr:  34%|███▍      | 34/100 [00:30<00:13,  4.76it/s]Finding best initial lr:  35%|███▌      | 35/100 [00:30<00:13,  4.77it/s]Finding best initial lr:  36%|███▌      | 36/100 [00:30<00:13,  4.77it/s]Finding best initial lr:  37%|███▋      | 37/100 [00:30<00:13,  4.77it/s]Finding best initial lr:  38%|███▊      | 38/100 [00:31<00:13,  4.76it/s]Finding best initial lr:  39%|███▉      | 39/100 [00:31<00:12,  4.76it/s]Finding best initial lr:  40%|████      | 40/100 [00:31<00:12,  4.76it/s]Finding best initial lr:  41%|████      | 41/100 [00:31<00:12,  4.76it/s]Finding best initial lr:  42%|████▏     | 42/100 [00:32<00:12,  4.77it/s]Finding best initial lr:  43%|████▎     | 43/100 [00:32<00:11,  4.77it/s]Finding best initial lr:  44%|████▍     | 44/100 [00:32<00:11,  4.77it/s]Finding best initial lr:  45%|████▌     | 45/100 [00:32<00:11,  4.77it/s]Finding best initial lr:  46%|████▌     | 46/100 [00:32<00:11,  4.77it/s]Finding best initial lr:  47%|████▋     | 47/100 [00:33<00:11,  4.77it/s]Finding best initial lr:  48%|████▊     | 48/100 [00:33<00:10,  4.77it/s]Finding best initial lr:  49%|████▉     | 49/100 [00:33<00:10,  4.77it/s]Finding best initial lr:  50%|█████     | 50/100 [00:33<00:10,  4.77it/s]Finding best initial lr:  51%|█████     | 51/100 [00:33<00:10,  4.77it/s]Finding best initial lr:  52%|█████▏    | 52/100 [00:34<00:10,  4.74it/s]Finding best initial lr:  53%|█████▎    | 53/100 [00:34<00:09,  4.75it/s]Finding best initial lr:  54%|█████▍    | 54/100 [00:34<00:09,  4.75it/s]Finding best initial lr:  55%|█████▌    | 55/100 [00:34<00:09,  4.76it/s]Finding best initial lr:  56%|█████▌    | 56/100 [00:34<00:09,  4.76it/s]Finding best initial lr:  57%|█████▋    | 57/100 [00:35<00:09,  4.76it/s]Finding best initial lr:  58%|█████▊    | 58/100 [00:35<00:08,  4.76it/s]Finding best initial lr:  59%|█████▉    | 59/100 [00:35<00:08,  4.76it/s]Finding best initial lr:  60%|██████    | 60/100 [00:35<00:08,  4.76it/s]Finding best initial lr:  61%|██████    | 61/100 [00:36<00:08,  4.76it/s]Finding best initial lr:  62%|██████▏   | 62/100 [00:36<00:07,  4.76it/s]Finding best initial lr:  63%|██████▎   | 63/100 [00:36<00:07,  4.77it/s]Finding best initial lr:  64%|██████▍   | 64/100 [00:36<00:07,  4.76it/s]Finding best initial lr:  65%|██████▌   | 65/100 [00:36<00:07,  4.77it/s]Finding best initial lr:  66%|██████▌   | 66/100 [00:37<00:07,  4.77it/s]Finding best initial lr:  67%|██████▋   | 67/100 [00:37<00:06,  4.76it/s]Finding best initial lr:  68%|██████▊   | 68/100 [00:37<00:06,  4.77it/s]Finding best initial lr:  69%|██████▉   | 69/100 [00:37<00:06,  4.77it/s]Finding best initial lr:  70%|███████   | 70/100 [00:37<00:06,  4.77it/s]Finding best initial lr:  71%|███████   | 71/100 [00:38<00:06,  4.77it/s]Finding best initial lr:  72%|███████▏  | 72/100 [00:38<00:05,  4.77it/s]Finding best initial lr:  73%|███████▎  | 73/100 [00:38<00:05,  4.77it/s]Finding best initial lr:  74%|███████▍  | 74/100 [00:38<00:05,  4.77it/s]Finding best initial lr:  75%|███████▌  | 75/100 [00:38<00:05,  4.77it/s]Finding best initial lr:  76%|███████▌  | 76/100 [00:39<00:05,  4.77it/s]Finding best initial lr:  77%|███████▋  | 77/100 [00:39<00:04,  4.77it/s]Finding best initial lr:  78%|███████▊  | 78/100 [00:39<00:04,  4.77it/s]Finding best initial lr:  79%|███████▉  | 79/100 [00:39<00:04,  4.77it/s]Finding best initial lr:  80%|████████  | 80/100 [00:40<00:04,  4.76it/s]Finding best initial lr:  81%|████████  | 81/100 [00:40<00:03,  4.77it/s]Finding best initial lr:  82%|████████▏ | 82/100 [00:40<00:03,  4.77it/s]Finding best initial lr:  83%|████████▎ | 83/100 [00:40<00:03,  4.77it/s]Finding best initial lr:  84%|████████▍ | 84/100 [00:40<00:03,  4.77it/s]Finding best initial lr:  85%|████████▌ | 85/100 [00:41<00:03,  4.77it/s]Finding best initial lr:  86%|████████▌ | 86/100 [00:41<00:02,  4.77it/s]Finding best initial lr:  87%|████████▋ | 87/100 [00:41<00:02,  4.77it/s]Finding best initial lr:  88%|████████▊ | 88/100 [00:41<00:02,  4.77it/s]Finding best initial lr:  89%|████████▉ | 89/100 [00:41<00:02,  4.77it/s]Finding best initial lr:  90%|█████████ | 90/100 [00:42<00:02,  4.77it/s]Finding best initial lr:  91%|█████████ | 91/100 [00:42<00:01,  4.77it/s]Finding best initial lr:  92%|█████████▏| 92/100 [00:42<00:01,  4.77it/s]Finding best initial lr:  93%|█████████▎| 93/100 [00:42<00:01,  4.77it/s]Finding best initial lr:  94%|█████████▍| 94/100 [00:42<00:01,  4.77it/s]Finding best initial lr:  95%|█████████▌| 95/100 [00:43<00:01,  4.77it/s]Finding best initial lr:  96%|█████████▌| 96/100 [00:43<00:00,  4.77it/s]Finding best initial lr:  97%|█████████▋| 97/100 [00:43<00:00,  4.77it/s]Finding best initial lr:  98%|█████████▊| 98/100 [00:43<00:00,  4.77it/s]Finding best initial lr:  99%|█████████▉| 99/100 [00:43<00:00,  4.75it/s]Finding best initial lr: 100%|██████████| 100/100 [00:44<00:00,  4.76it/s]`Trainer.fit` stopped: `max_steps=100` reached.
Finding best initial lr: 100%|██████████| 100/100 [00:44<00:00,  2.26it/s]
Learning rate set to 0.0003019951720402019
Restoring states from the checkpoint path at /gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/.lr_find_4b6ab718-64c6-4462-b752-93bd00460ad6.ckpt
Restored all states from the checkpoint at /gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/.lr_find_4b6ab718-64c6-4462-b752-93bd00460ad6.ckpt

  | Name  | Type            | Params | Mode 
--------------------------------------------------
0 | model | OptimizedModule | 10.8 M | train
--------------------------------------------------
10.8 M    Trainable params
0         Non-trainable params
10.8 M    Total params
43.053    Total estimated model params size (MB)
87        Modules in train mode
0         Modules in eval mode
Restored all states from the checkpoint at /gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/.lr_find_4b6ab718-64c6-4462-b752-93bd00460ad6.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/opt/conda/conda-bld/pytorch_1728945370933/work/aten/src/ATen/native/cuda/TensorCompare.cu:110: _assert_async_cuda_kernel: block: [0,0,0], thread: [0,0,0] Assertion `probability tensor contains either `inf`, `nan` or element < 0` failed.
Traceback (most recent call last):
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1025, in _run_stage
    self.fit_loop.run()
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
    self.advance(data_fetcher)
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 167, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1306, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 137, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/optim/optimizer.py", line 487, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/optim/adamw.py", line 197, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/train.py", line 55, in training_step
    generated_sents = self.generate()
                      ^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/train.py", line 120, in generate
    y = self.model.generate(x, n_steps, temperature=1.0, do_sample=do_sample, top_k=top_k, top_p=top_p)[0]
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/gpt.py", line 497, in generate
    logits = self(idx_cond)  # (b, t, vocab_size)
             ^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/gpt.py", line 447, in forward
    x = block(x)    # Shape remains (b, t, n_embd)
        ^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/gpt.py", line 226, in forward
    out = x + self.attn(self.ln1(x))  # Shape: (B, T, C)
              ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/gpt.py", line 157, in forward
    q, k = self.apply_rotary_emb(q, k, T)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/gpt.py", line 119, in apply_rotary_emb
    freqs = torch.einsum("i,j->ij", seq_pos.squeeze(), self.inv_freq.to(device))  # Shape: (T, dim // 2)
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/train.py", line 209, in <module>
    train(args=args)
  File "/gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/train.py", line 202, in train
    trainer.fit(lightning_model)
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 68, in _call_and_handle_interrupt
    trainer._teardown()
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1004, in _teardown
    self.strategy.teardown()
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 531, in teardown
    _optimizers_to_device(self.optimizers, torch.device("cpu"))
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/lightning_fabric/utilities/optimizer.py", line 28, in _optimizers_to_device
    _optimizer_to_device(opt, device)
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/lightning_fabric/utilities/optimizer.py", line 42, in _optimizer_to_device
    v[key] = move_data_to_device(val, device)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/lightning_fabric/utilities/apply_func.py", line 110, in move_data_to_device
    return apply_to_collection(batch, dtype=_TransferableDataType, function=batch_to)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/lightning_utilities/core/apply_func.py", line 64, in apply_to_collection
    return function(data, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/lightning_fabric/utilities/apply_func.py", line 104, in batch_to
    data_output = data.to(device, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

srun: error: gcn3: task 0: Exited with exit code 1
srun: Terminating StepId=8692359.0

JOB STATISTICS
==============
Job ID: 8692359
Cluster: snellius
User/Group: scur2773/scur2773
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 9
CPU Utilized: 00:04:31
CPU Efficiency: 10.91% of 00:41:24 core-walltime
Job Wall-clock time: 00:04:36
Memory Utilized: 1.55 GB
Memory Efficiency: 2.58% of 60.00 GB
