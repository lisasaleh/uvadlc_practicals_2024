============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
[rank: 0] Seed set to 0
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Namespace(txt_file='./assets/book_EN_grimms_fairy_tales.txt', model_type='gpt-mini', block_size=128, use_pretrained=False, abs_emb=False, train_batch_size=128, generate_batch_size=5, generate_every_n_steps=1000, learning_rate=0.0005, weight_decay=0.1, betas=(0.9, 0.95), num_epochs=5, clip_grad_norm=1.0, log_dir='./logs', seed=0, num_workers=8, progress_bar=False, use_flash_attn=False, precision='32', compile=True, pretrained_tokenizer=False, device='cuda')
data has 540241 characters, 87 unique.
True False
number of parameters: 10.73M
running on device cuda
Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:167: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Device that is available: cuda
Input tensor device before moving: cuda:0
Input tensor device after moving: cuda:0
Token embeddings device: cuda:0
Block output device: cuda:0
After layer normalization device: cuda:0
Logits device: cuda:0
Device that is available: cuda
Input tensor device before moving: cpu
Input tensor device after moving: cuda:0
Token embeddings device: cuda:0
Block output device: cuda:0
After layer normalization device: cuda:0
Logits device: cuda:0
torch.Size([1, 87])
Traceback (most recent call last):
  File "/gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/train.py", line 209, in <module>
    train(args=args)
  File "/gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/train.py", line 202, in train
    trainer.fit(lightning_model)
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 961, in _run
    call._call_callback_hooks(self, "on_fit_start")
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 218, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/callbacks/lr_finder.py", line 130, in on_fit_start
    self.lr_find(trainer, pl_module)
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/callbacks/lr_finder.py", line 113, in lr_find
    self.optimal_lr = _lr_find(
                      ^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/tuner/lr_finder.py", line 278, in _lr_find
    _try_loop_run(trainer, params)
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/tuner/lr_finder.py", line 523, in _try_loop_run
    loop.run()
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
    self.advance(data_fetcher)
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 167, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1306, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 137, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/optim/optimizer.py", line 487, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/optim/adamw.py", line 197, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/train.py", line 55, in training_step
    generated_sents = self.generate()
                      ^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/train.py", line 120, in generate
    y = self.model.generate(x, n_steps, temperature=1.0, do_sample=do_sample, top_k=top_k, top_p=top_p)[0]
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2773/.conda/envs/dl2024/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home6/scur2773/uvadlc_practicals_2024/assignment2/part2/gpt.py", line 548, in generate
    idx = torch.cat((idx, idx_next), dim=1)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_CUDA_cat)
Finding best initial lr:   0%|          | 0/100 [00:21<?, ?it/s]
srun: error: gcn20: task 0: Exited with exit code 1
srun: Terminating StepId=8813864.0

JOB STATISTICS
==============
Job ID: 8813864
Cluster: snellius
User/Group: scur2773/scur2773
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:31
CPU Efficiency: 3.38% of 00:15:18 core-walltime
Job Wall-clock time: 00:00:51
Memory Utilized: 1.39 GB
Memory Efficiency: 1.15% of 120.00 GB
